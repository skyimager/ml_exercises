{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for data handling\n",
    "pd.options.display.max_rows = 999 #set the max no of rows you can see. \n",
    "pd.set_option('display.max_columns', 999) #another way to do the same thing\n",
    "\n",
    "import seaborn as sns #for higher-level  visualisation\n",
    "import numpy as np #for matrix operation\n",
    "import matplotlib.pyplot as plt #for lower-level visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>a_5</th>\n",
       "      <th>a_6</th>\n",
       "      <th>a_7</th>\n",
       "      <th>a_8</th>\n",
       "      <th>a_9</th>\n",
       "      <th>a_10</th>\n",
       "      <th>a_11</th>\n",
       "      <th>a_12</th>\n",
       "      <th>a_13</th>\n",
       "      <th>a_14</th>\n",
       "      <th>a_15</th>\n",
       "      <th>a_16</th>\n",
       "      <th>a_17</th>\n",
       "      <th>a_18</th>\n",
       "      <th>a_19</th>\n",
       "      <th>a_20</th>\n",
       "      <th>a_21</th>\n",
       "      <th>a_22</th>\n",
       "      <th>a_23</th>\n",
       "      <th>a_24</th>\n",
       "      <th>a_25</th>\n",
       "      <th>a_26</th>\n",
       "      <th>a_27</th>\n",
       "      <th>a_28</th>\n",
       "      <th>a_29</th>\n",
       "      <th>a_30</th>\n",
       "      <th>a_31</th>\n",
       "      <th>a_32</th>\n",
       "      <th>a_33</th>\n",
       "      <th>a_34</th>\n",
       "      <th>a_35</th>\n",
       "      <th>a_36</th>\n",
       "      <th>a_37</th>\n",
       "      <th>a_38</th>\n",
       "      <th>a_39</th>\n",
       "      <th>a_40</th>\n",
       "      <th>a_41</th>\n",
       "      <th>a_42</th>\n",
       "      <th>a_43</th>\n",
       "      <th>a_44</th>\n",
       "      <th>a_45</th>\n",
       "      <th>a_46</th>\n",
       "      <th>a_47</th>\n",
       "      <th>a_48</th>\n",
       "      <th>a_49</th>\n",
       "      <th>a_50</th>\n",
       "      <th>a_51</th>\n",
       "      <th>a_52</th>\n",
       "      <th>a_53</th>\n",
       "      <th>a_54</th>\n",
       "      <th>a_55</th>\n",
       "      <th>a_56</th>\n",
       "      <th>a_57</th>\n",
       "      <th>a_58</th>\n",
       "      <th>a_59</th>\n",
       "      <th>a_60</th>\n",
       "      <th>a_61</th>\n",
       "      <th>a_62</th>\n",
       "      <th>a_63</th>\n",
       "      <th>a_64</th>\n",
       "      <th>a_65</th>\n",
       "      <th>a_66</th>\n",
       "      <th>a_67</th>\n",
       "      <th>a_68</th>\n",
       "      <th>a_69</th>\n",
       "      <th>a_70</th>\n",
       "      <th>a_71</th>\n",
       "      <th>a_72</th>\n",
       "      <th>a_73</th>\n",
       "      <th>a_74</th>\n",
       "      <th>a_75</th>\n",
       "      <th>a_76</th>\n",
       "      <th>a_77</th>\n",
       "      <th>a_78</th>\n",
       "      <th>a_79</th>\n",
       "      <th>a_80</th>\n",
       "      <th>a_81</th>\n",
       "      <th>a_82</th>\n",
       "      <th>a_83</th>\n",
       "      <th>a_84</th>\n",
       "      <th>a_85</th>\n",
       "      <th>a_86</th>\n",
       "      <th>a_87</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372447</th>\n",
       "      <td>4044</td>\n",
       "      <td>18.17</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ad</td>\n",
       "      <td>sm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417339</th>\n",
       "      <td>2636</td>\n",
       "      <td>299.00</td>\n",
       "      <td>4.7468</td>\n",
       "      <td>237</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.989443</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ie</td>\n",
       "      <td>or</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85042</th>\n",
       "      <td>4044</td>\n",
       "      <td>89.99</td>\n",
       "      <td>4.8136</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.610583</td>\n",
       "      <td>1.610833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.310867</td>\n",
       "      <td>7.155683</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.501800</td>\n",
       "      <td>4.300610</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.501800</td>\n",
       "      <td>4.300610</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ad</td>\n",
       "      <td>oc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96752</th>\n",
       "      <td>1115193</td>\n",
       "      <td>8.47</td>\n",
       "      <td>4.2334</td>\n",
       "      <td>347</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.181926</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.372750</td>\n",
       "      <td>3.373000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.372750</td>\n",
       "      <td>3.373000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>34.388167</td>\n",
       "      <td>11.462972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>49.589083</td>\n",
       "      <td>9.918067</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ws</td>\n",
       "      <td>oc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184530</th>\n",
       "      <td>4044</td>\n",
       "      <td>55.00</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032710</td>\n",
       "      <td>0.080269</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.934133</td>\n",
       "      <td>1.934383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.934133</td>\n",
       "      <td>1.934383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.934133</td>\n",
       "      <td>1.934383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14.307583</td>\n",
       "      <td>4.769444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>ws</td>\n",
       "      <td>oc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            a_0     a_1     a_2  a_3       a_4       a_5  a_6  a_7  a_8  \\\n",
       "372447     4044   18.17  3.3333    3  0.000000  0.007463    1    2    1   \n",
       "417339     2636  299.00  4.7468  237  0.007862  0.989443    5    2    1   \n",
       "85042      4044   89.99  4.8136   59  0.000000  0.189115    3    2    0   \n",
       "96752   1115193    8.47  4.2334  347  0.005391  0.181926    1    2    0   \n",
       "184530     4044   55.00  5.0000    3  0.032710  0.080269    4    2    1   \n",
       "\n",
       "          a_9   a_10   a_11   a_12   a_13   a_14   a_15  a_16  a_17  a_18  \\\n",
       "372447  False  False  False   True  False  False   True     1     1     0   \n",
       "417339  False  False  False  False  False   True   True     1     1     0   \n",
       "85042   False  False  False   True  False  False   True     0     4     0   \n",
       "96752   False   True  False   True  False  False  False     2     6     0   \n",
       "184530  False  False  False   True  False  False  False     2     8     0   \n",
       "\n",
       "        a_19  a_20  a_21  a_22      a_23      a_24  a_25  a_26  a_27  a_28  \\\n",
       "372447     0    18     2     0  0.000000  0.000250     1     0     0     0   \n",
       "417339     0    15     2     0  0.003433  0.003683     0     0     0     0   \n",
       "85042      0    22     2     0  1.610583  1.610833     0     0     0     0   \n",
       "96752      0    20     2     3  3.372750  3.373000     0     0     0     0   \n",
       "184530     0     5     2     5  1.934133  1.934383     0     0     0     0   \n",
       "\n",
       "        a_29  a_30  a_31  a_32  a_33  a_34  a_35  a_36  a_37  a_38  a_39  \\\n",
       "372447     1     1     0     0     0     1     1     1     0     0     0   \n",
       "417339     4     0     0     0     0     1     1     1     0     0     0   \n",
       "85042      4     0     0     0     0     2     9    17     0     0     2   \n",
       "96752      4     0     0     0     0     1     2     6     0     0     3   \n",
       "184530     4     0     0     0     0     1     2     8     0     0     5   \n",
       "\n",
       "             a_40      a_41  a_42  a_43  a_44  a_45  a_46  a_47  a_48  a_49  \\\n",
       "372447   0.000000  0.000250     1     0     0     0     1     1     0     0   \n",
       "417339   0.003433  0.003683     0     0     0     0     4     0     0     0   \n",
       "85042   14.310867  7.155683     6     0    97     0     1     6     0    96   \n",
       "96752    3.372750  3.373000     0     0     0     0     4     0     0     0   \n",
       "184530   1.934133  1.934383     0     0     0     0     4     0     0     0   \n",
       "\n",
       "        a_50  a_51  a_52  a_53  a_54  a_55  a_56       a_57       a_58  a_59  \\\n",
       "372447     0     1     1     1     0     0     0   0.000000   0.000250     1   \n",
       "417339     0     1     1     1     0     0     0   0.003433   0.003683     0   \n",
       "85042      0     5    20    31     0     0     4  21.501800   4.300610    14   \n",
       "96752      0     3    24    69    10    15    20  34.388167  11.462972     0   \n",
       "184530     0     1     2     8     0     0     5   1.934133   1.934383     0   \n",
       "\n",
       "        a_60  a_61  a_62  a_63  a_64  a_65  a_66  a_67  a_68  a_69  a_70  \\\n",
       "372447     0     0     0     1     1     0     0     0     1     1     1   \n",
       "417339     0     0     0     4     0     0     0     0     1     1     1   \n",
       "85042      0   181     0     1    11     0   146     0     5    20    31   \n",
       "96752      0     0     0     4     0     0     0     0     5    33    81   \n",
       "184530     0     0     0     4     0     0     0     0     3     5    23   \n",
       "\n",
       "        a_71  a_72  a_73       a_74      a_75  a_76  a_77  a_78  a_79  a_80  \\\n",
       "372447     0     0     0   0.000000  0.000250     1     0     0     0     1   \n",
       "417339     0     0     0   0.003433  0.003683     0     0     0     0     4   \n",
       "85042      0     0     4  21.501800  4.300610    14     0   181     0     1   \n",
       "96752     12    16    20  49.589083  9.918067     1     0     0     0     4   \n",
       "184530     0     0    14  14.307583  4.769444     0     0     0     0     4   \n",
       "\n",
       "        a_81  a_82  a_83  a_84   a_85 a_86 a_87  label  \n",
       "372447     1     0     0     0  False   ad   sm      0  \n",
       "417339     0     0     0     0  False   ie   or      0  \n",
       "85042     11     0   146     0  False   ad   oc      0  \n",
       "96752      1     0     0     0  False   ws   oc      0  \n",
       "184530     0     0     0     0  False   ws   oc      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Dtypes Check and Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('float64'), dtype('bool'), dtype('O')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.unique() #different types of features we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Fix boolean datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_df = train_df.select_dtypes(include=\"bool\") #take out bool seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_9', 'a_10', 'a_11', 'a_12', 'a_13', 'a_14', 'a_15', 'a_85'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_df.columns #check all the boolean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_9\n",
      "a_10\n",
      "a_11\n",
      "a_12\n",
      "a_13\n",
      "a_14\n",
      "a_15\n",
      "a_85\n"
     ]
    }
   ],
   "source": [
    "for column in bool_df.columns:\n",
    "    print(column)\n",
    "    del train_df[column]\n",
    "    train_df[column] = np.where(bool_df[column] == False,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['a_9'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the remaining data types to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('float64'), dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Fix \"object\" datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df = train_df.select_dtypes(include=\"object\") #take out object seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_86', 'a_87'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_df.columns #check all object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ws', 'ie', 'mc', 'tt', 'ad', 'id', 'or'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"a_86\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ws    156543\n",
       "ie    142909\n",
       "ad    120996\n",
       "mc     28944\n",
       "id     25414\n",
       "or     14151\n",
       "tt     11043\n",
       "Name: a_86, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"a_86\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sm', 'oc', 'ae', 'dy', 'el', 'or'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"a_87\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oc    279315\n",
       "sm    169816\n",
       "dy     25896\n",
       "ae     14792\n",
       "el      5094\n",
       "or      5087\n",
       "Name: a_87, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"a_87\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_86\n",
      "a_87\n"
     ]
    }
   ],
   "source": [
    "for column in object_df.columns:\n",
    "    print(column)\n",
    "    dummy = pd.get_dummies(train_df[column], prefix = column, drop_first = True)\n",
    "    train_df = pd.concat([train_df, dummy], axis = 1)\n",
    "    train_df.drop(column, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>a_5</th>\n",
       "      <th>a_6</th>\n",
       "      <th>a_7</th>\n",
       "      <th>a_8</th>\n",
       "      <th>a_16</th>\n",
       "      <th>a_17</th>\n",
       "      <th>a_18</th>\n",
       "      <th>a_19</th>\n",
       "      <th>a_20</th>\n",
       "      <th>a_21</th>\n",
       "      <th>a_22</th>\n",
       "      <th>a_23</th>\n",
       "      <th>a_24</th>\n",
       "      <th>a_25</th>\n",
       "      <th>a_26</th>\n",
       "      <th>a_27</th>\n",
       "      <th>a_28</th>\n",
       "      <th>a_29</th>\n",
       "      <th>a_30</th>\n",
       "      <th>a_31</th>\n",
       "      <th>a_32</th>\n",
       "      <th>a_33</th>\n",
       "      <th>a_34</th>\n",
       "      <th>a_35</th>\n",
       "      <th>a_36</th>\n",
       "      <th>a_37</th>\n",
       "      <th>a_38</th>\n",
       "      <th>a_39</th>\n",
       "      <th>a_40</th>\n",
       "      <th>a_41</th>\n",
       "      <th>a_42</th>\n",
       "      <th>a_43</th>\n",
       "      <th>a_44</th>\n",
       "      <th>a_45</th>\n",
       "      <th>a_46</th>\n",
       "      <th>a_47</th>\n",
       "      <th>a_48</th>\n",
       "      <th>a_49</th>\n",
       "      <th>a_50</th>\n",
       "      <th>a_51</th>\n",
       "      <th>a_52</th>\n",
       "      <th>a_53</th>\n",
       "      <th>a_54</th>\n",
       "      <th>a_55</th>\n",
       "      <th>a_56</th>\n",
       "      <th>a_57</th>\n",
       "      <th>a_58</th>\n",
       "      <th>a_59</th>\n",
       "      <th>a_60</th>\n",
       "      <th>a_61</th>\n",
       "      <th>a_62</th>\n",
       "      <th>a_63</th>\n",
       "      <th>a_64</th>\n",
       "      <th>a_65</th>\n",
       "      <th>a_66</th>\n",
       "      <th>a_67</th>\n",
       "      <th>a_68</th>\n",
       "      <th>a_69</th>\n",
       "      <th>a_70</th>\n",
       "      <th>a_71</th>\n",
       "      <th>a_72</th>\n",
       "      <th>a_73</th>\n",
       "      <th>a_74</th>\n",
       "      <th>a_75</th>\n",
       "      <th>a_76</th>\n",
       "      <th>a_77</th>\n",
       "      <th>a_78</th>\n",
       "      <th>a_79</th>\n",
       "      <th>a_80</th>\n",
       "      <th>a_81</th>\n",
       "      <th>a_82</th>\n",
       "      <th>a_83</th>\n",
       "      <th>a_84</th>\n",
       "      <th>label</th>\n",
       "      <th>a_9</th>\n",
       "      <th>a_10</th>\n",
       "      <th>a_11</th>\n",
       "      <th>a_12</th>\n",
       "      <th>a_13</th>\n",
       "      <th>a_14</th>\n",
       "      <th>a_15</th>\n",
       "      <th>a_85</th>\n",
       "      <th>a_86_id</th>\n",
       "      <th>a_86_ie</th>\n",
       "      <th>a_86_mc</th>\n",
       "      <th>a_86_or</th>\n",
       "      <th>a_86_tt</th>\n",
       "      <th>a_86_ws</th>\n",
       "      <th>a_87_dy</th>\n",
       "      <th>a_87_el</th>\n",
       "      <th>a_87_oc</th>\n",
       "      <th>a_87_or</th>\n",
       "      <th>a_87_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312603</th>\n",
       "      <td>5438</td>\n",
       "      <td>18.74</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>136.491250</td>\n",
       "      <td>136.491500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>253.549167</td>\n",
       "      <td>126.774833</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>253.549167</td>\n",
       "      <td>126.774833</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>253.549167</td>\n",
       "      <td>126.774833</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66900</th>\n",
       "      <td>1072864</td>\n",
       "      <td>12.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431785</th>\n",
       "      <td>-1</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.659538</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185082</th>\n",
       "      <td>5438</td>\n",
       "      <td>13.79</td>\n",
       "      <td>4.8095</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570714</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.041867</td>\n",
       "      <td>1.042117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>30.798283</td>\n",
       "      <td>15.399392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>30.798283</td>\n",
       "      <td>15.399392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>30.798283</td>\n",
       "      <td>15.399392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200644</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.510083</td>\n",
       "      <td>4.510333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.090883</td>\n",
       "      <td>7.545692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.090883</td>\n",
       "      <td>5.030544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>87.448833</td>\n",
       "      <td>10.931354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            a_0    a_1     a_2  a_3       a_4       a_5  a_6  a_7  a_8  a_16  \\\n",
       "312603     5438  18.74  0.0000    0  0.000000  0.008464    3    2    0    98   \n",
       "66900   1072864  12.81  0.0000    0  0.000000  0.018111    2    2    0     1   \n",
       "431785       -1   6.94  0.0000    0  0.002332  0.659538    1    2    0     1   \n",
       "185082     5438  13.79  4.8095   21  0.000000  0.570714    2    2    0     1   \n",
       "200644       -1   0.00  5.0000    1  0.000000  0.078631    1    1    0     2   \n",
       "\n",
       "        a_17  a_18  a_19  a_20  a_21  a_22        a_23        a_24  a_25  \\\n",
       "312603    99     0     0     0     2     1  136.491250  136.491500     0   \n",
       "66900      1     0     0    19     2     0    0.000000    0.000250     1   \n",
       "431785     1     0     0    10     2     0    0.000000    0.000250     0   \n",
       "185082     5     0     0    23     2     3    1.041867    1.042117     0   \n",
       "200644     6     0     0     8     2     0    4.510083    4.510333     0   \n",
       "\n",
       "        a_26  a_27  a_28  a_29  a_30  a_31  a_32  a_33  a_34  a_35  a_36  \\\n",
       "312603     0     0     0     4     0     0     0     0     2   173   179   \n",
       "66900      0     0     0     1     1     0     0     0     1     1     1   \n",
       "431785     0     0     0     4     0     0     0     0     1     1     1   \n",
       "185082     0     0     0     4     0     0     0     0     2    18    75   \n",
       "200644     0     0     0     4     0     0     0     0     2     3    10   \n",
       "\n",
       "        a_37  a_38  a_39        a_40        a_41  a_42  a_43  a_44  a_45  \\\n",
       "312603     0     0     6  253.549167  126.774833     3     0     0     0   \n",
       "66900      0     0     0    0.000000    0.000250     1     0     0     0   \n",
       "431785     0     0     0    0.000000    0.000250     0     0     0     0   \n",
       "185082     4     9    29   30.798283   15.399392     1     0     0     0   \n",
       "200644     0     0     0   15.090883    7.545692     0     0     0     0   \n",
       "\n",
       "        a_46  a_47  a_48  a_49  a_50  a_51  a_52  a_53  a_54  a_55  a_56  \\\n",
       "312603     4     1     0     0     0     2   173   179     0     0     6   \n",
       "66900      1     1     0     0     0     1     1     1     0     0     0   \n",
       "431785     4     0     0     0     0     1     1     1     0     0     0   \n",
       "185082     4     1     0     0     0     2    18    75     4     9    29   \n",
       "200644     4     0     0     0     0     3     3    11     0     0     1   \n",
       "\n",
       "              a_57        a_58  a_59  a_60  a_61  a_62  a_63  a_64  a_65  \\\n",
       "312603  253.549167  126.774833     3     0     0     0     4     1     0   \n",
       "66900     0.000000    0.000250     1     0     0     0     1     1     0   \n",
       "431785    0.000000    0.000250     0     0     0     0     4     0     0   \n",
       "185082   30.798283   15.399392     1     0     0     0     4     1     0   \n",
       "200644   15.090883    5.030544     0     0     0     0     4     0     0   \n",
       "\n",
       "        a_66  a_67  a_68  a_69  a_70  a_71  a_72  a_73        a_74  \\\n",
       "312603     0     0     2   173   179     0     0     6  253.549167   \n",
       "66900      0     0     1     1     1     0     0     0    0.000000   \n",
       "431785     0     0     1     1     1     0     0     0    0.000000   \n",
       "185082     0     0     2    18    75     4     9    29   30.798283   \n",
       "200644     0     0     8    53   162    13    11    13   87.448833   \n",
       "\n",
       "              a_75  a_76  a_77  a_78  a_79  a_80  a_81  a_82  a_83  a_84  \\\n",
       "312603  126.774833     3     0     0     0     4     1     0     0     0   \n",
       "66900     0.000250     1     0     0     0     1     1     0     0     0   \n",
       "431785    0.000250     0     0     0     0     4     0     0     0     0   \n",
       "185082   15.399392     1     0     0     0     4     1     0     0     0   \n",
       "200644   10.931354     0     0     0     0     4     0     0     0     0   \n",
       "\n",
       "        label  a_9  a_10  a_11  a_12  a_13  a_14  a_15  a_85  a_86_id  \\\n",
       "312603      0    0     0     0     0     1     0     0     0        0   \n",
       "66900       0    0     1     0     0     0     1     0     0        0   \n",
       "431785      0    0     0     0     0     0     1     0     0        0   \n",
       "185082      0    0     1     0     0     0     1     1     0        0   \n",
       "200644      0    0     1     0     1     0     0     0     0        0   \n",
       "\n",
       "        a_86_ie  a_86_mc  a_86_or  a_86_tt  a_86_ws  a_87_dy  a_87_el  \\\n",
       "312603        0        0        1        0        0        0        0   \n",
       "66900         0        0        0        0        1        0        0   \n",
       "431785        0        0        0        0        1        0        0   \n",
       "185082        1        0        0        0        0        0        0   \n",
       "200644        0        0        0        0        1        0        0   \n",
       "\n",
       "        a_87_oc  a_87_or  a_87_sm  \n",
       "312603        1        0        0  \n",
       "66900         0        0        1  \n",
       "431785        0        0        1  \n",
       "185082        1        0        0  \n",
       "200644        1        0        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    498275\n",
       "1      1725\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Defining train test split  (Ran till this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_df.columns)\n",
    "features.remove(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 97)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df[features].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df[\"label\"].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split (X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([398592,   1408]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([99683,   317]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 97)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler().fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideally the normalised data should have mean of zero and a standard deviation of one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.535334115468208e-15, 0.9896370260349382)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train), np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 56)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.99)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([398592,   1408]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([99683,   317]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As the data is imbalanced, we will use smote for handling imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_train_balanced, Y_train_balanced = SMOTE(sampling_strategy=0.1,\n",
    "                                k_neighbors=3).fit_resample(X_train_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((438451, 56), (438451,))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_balanced.shape, Y_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([398592,  39859]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train_balanced,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Pipeline for test data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 56)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca = pca.transform(X_test)\n",
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 : Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshav.somani/.py_venv/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the model\n",
    "model = LogisticRegression(solver=\"sag\", max_iter=500)\n",
    "\n",
    "# feeding the training data into the model\n",
    "model.fit(X_train_balanced, Y_train_balanced)\n",
    "\n",
    "# predicting the test set results\n",
    "Y_pred = model.predict_proba(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_threshold = (Y_pred[:,1] >= 0.5).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.9116047175168948\n",
      "Testing accuracy : 0.07889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14     99683\n",
      "           1       0.00      0.96      0.01       317\n",
      "\n",
      "    accuracy                           0.08    100000\n",
      "   macro avg       0.50      0.52      0.07    100000\n",
      "weighted avg       1.00      0.08      0.14    100000\n",
      "\n",
      "[[ 7586 92097]\n",
      " [   14   303]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy :\", model.score(X_train_balanced, Y_train_balanced))\n",
    "print(\"Testing accuracy :\", model.score(X_test_pca, Y_test))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_test, y_pred_threshold))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_test, y_pred_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model.score(X_train_balanced, Y_train_balanced))\n",
    "print(\"Testing accuracy :\", model.score(X_test_pca, Y_test))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.02638\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.01575\n",
      "[2]\tvalidation_0-error:0.01402\n",
      "[3]\tvalidation_0-error:0.00925\n",
      "[4]\tvalidation_0-error:0.00774\n",
      "[5]\tvalidation_0-error:0.00532\n",
      "[6]\tvalidation_0-error:0.00376\n",
      "[7]\tvalidation_0-error:0.00391\n",
      "[8]\tvalidation_0-error:0.00362\n",
      "[9]\tvalidation_0-error:0.00359\n",
      "[10]\tvalidation_0-error:0.00536\n",
      "[11]\tvalidation_0-error:0.00475\n",
      "[12]\tvalidation_0-error:0.02705\n",
      "[13]\tvalidation_0-error:0.02763\n",
      "[14]\tvalidation_0-error:0.07888\n",
      "[15]\tvalidation_0-error:0.07714\n",
      "[16]\tvalidation_0-error:0.83772\n",
      "[17]\tvalidation_0-error:0.79963\n",
      "[18]\tvalidation_0-error:0.78122\n",
      "[19]\tvalidation_0-error:0.7461\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-error:0.00359\n",
      "\n",
      "Training accuracy : 0.9185359367409357\n",
      "Testing accuracy : 0.99641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99683\n",
      "           1       0.00      0.00      0.00       317\n",
      "\n",
      "    accuracy                           1.00    100000\n",
      "   macro avg       0.50      0.50      0.50    100000\n",
      "weighted avg       0.99      1.00      1.00    100000\n",
      "\n",
      "[[99641    42]\n",
      " [  317     0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_set = [(X_test_pca, Y_test)]\n",
    "\n",
    "model_xgbs = xgb.XGBClassifier(gamma=0.024, learning_rate=0.3, \n",
    "                          max_depth=6,\n",
    "                          nthread=4,\n",
    "                          n_estimators=1000)\n",
    "\n",
    "model_xgbs.silent=False\n",
    "\n",
    "model_xgbs.fit(X_train_balanced, Y_train_balanced, early_stopping_rounds=10, \n",
    "          eval_set=eval_set,\n",
    "          verbose=True) #https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "# predicting the test set results\n",
    "Y_pred = model_xgbs.predict(X_test_pca)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model_xgbs.score(X_train_balanced, Y_train_balanced))\n",
    "print(\"Testing accuracy :\", model_xgbs.score(X_test_pca, Y_test))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 98 columns):\n",
      "a_0        500000 non-null int64\n",
      "a_1        500000 non-null float64\n",
      "a_2        500000 non-null float64\n",
      "a_3        500000 non-null int64\n",
      "a_4        500000 non-null float64\n",
      "a_5        500000 non-null float64\n",
      "a_6        500000 non-null int64\n",
      "a_7        500000 non-null int64\n",
      "a_8        500000 non-null int64\n",
      "a_16       500000 non-null int64\n",
      "a_17       500000 non-null int64\n",
      "a_18       500000 non-null int64\n",
      "a_19       500000 non-null int64\n",
      "a_20       500000 non-null int64\n",
      "a_21       500000 non-null int64\n",
      "a_22       500000 non-null int64\n",
      "a_23       500000 non-null float64\n",
      "a_24       500000 non-null float64\n",
      "a_25       500000 non-null int64\n",
      "a_26       500000 non-null int64\n",
      "a_27       500000 non-null int64\n",
      "a_28       500000 non-null int64\n",
      "a_29       500000 non-null int64\n",
      "a_30       500000 non-null int64\n",
      "a_31       500000 non-null int64\n",
      "a_32       500000 non-null int64\n",
      "a_33       500000 non-null int64\n",
      "a_34       500000 non-null int64\n",
      "a_35       500000 non-null int64\n",
      "a_36       500000 non-null int64\n",
      "a_37       500000 non-null int64\n",
      "a_38       500000 non-null int64\n",
      "a_39       500000 non-null int64\n",
      "a_40       500000 non-null float64\n",
      "a_41       500000 non-null float64\n",
      "a_42       500000 non-null int64\n",
      "a_43       500000 non-null int64\n",
      "a_44       500000 non-null int64\n",
      "a_45       500000 non-null int64\n",
      "a_46       500000 non-null int64\n",
      "a_47       500000 non-null int64\n",
      "a_48       500000 non-null int64\n",
      "a_49       500000 non-null int64\n",
      "a_50       500000 non-null int64\n",
      "a_51       500000 non-null int64\n",
      "a_52       500000 non-null int64\n",
      "a_53       500000 non-null int64\n",
      "a_54       500000 non-null int64\n",
      "a_55       500000 non-null int64\n",
      "a_56       500000 non-null int64\n",
      "a_57       500000 non-null float64\n",
      "a_58       500000 non-null float64\n",
      "a_59       500000 non-null int64\n",
      "a_60       500000 non-null int64\n",
      "a_61       500000 non-null int64\n",
      "a_62       500000 non-null int64\n",
      "a_63       500000 non-null int64\n",
      "a_64       500000 non-null int64\n",
      "a_65       500000 non-null int64\n",
      "a_66       500000 non-null int64\n",
      "a_67       500000 non-null int64\n",
      "a_68       500000 non-null int64\n",
      "a_69       500000 non-null int64\n",
      "a_70       500000 non-null int64\n",
      "a_71       500000 non-null int64\n",
      "a_72       500000 non-null int64\n",
      "a_73       500000 non-null int64\n",
      "a_74       500000 non-null float64\n",
      "a_75       500000 non-null float64\n",
      "a_76       500000 non-null int64\n",
      "a_77       500000 non-null int64\n",
      "a_78       500000 non-null int64\n",
      "a_79       500000 non-null int64\n",
      "a_80       500000 non-null int64\n",
      "a_81       500000 non-null int64\n",
      "a_82       500000 non-null int64\n",
      "a_83       500000 non-null int64\n",
      "a_84       500000 non-null int64\n",
      "label      500000 non-null int64\n",
      "a_9        500000 non-null int64\n",
      "a_10       500000 non-null int64\n",
      "a_11       500000 non-null int64\n",
      "a_12       500000 non-null int64\n",
      "a_13       500000 non-null int64\n",
      "a_14       500000 non-null int64\n",
      "a_15       500000 non-null int64\n",
      "a_85       500000 non-null int64\n",
      "a_86_id    500000 non-null uint8\n",
      "a_86_ie    500000 non-null uint8\n",
      "a_86_mc    500000 non-null uint8\n",
      "a_86_or    500000 non-null uint8\n",
      "a_86_tt    500000 non-null uint8\n",
      "a_86_ws    500000 non-null uint8\n",
      "a_87_dy    500000 non-null uint8\n",
      "a_87_el    500000 non-null uint8\n",
      "a_87_oc    500000 non-null uint8\n",
      "a_87_or    500000 non-null uint8\n",
      "a_87_sm    500000 non-null uint8\n",
      "dtypes: float64(12), int64(75), uint8(11)\n",
      "memory usage: 337.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[{'a_23', 'a_24'}],\n",
       "       [{'a_27', 'a_32'}],\n",
       "       [{'a_44', 'a_49'}],\n",
       "       [{'a_50', 'a_45'}],\n",
       "       [{'a_36', 'a_53', 'a_35', 'a_52'}],\n",
       "       [{'a_66', 'a_61'}],\n",
       "       [{'a_67', 'a_62'}],\n",
       "       [{'a_70', 'a_69'}],\n",
       "       [{'a_38', 'a_55', 'a_54', 'a_37', 'a_19', 'a_71', 'a_18'}],\n",
       "       [{'a_73', 'a_56'}],\n",
       "       [{'a_58', 'a_75'}],\n",
       "       [{'a_81', 'a_64', 'a_76'}],\n",
       "       [{'a_82', 'a_26', 'a_77', 'a_48', 'a_60', 'a_31', 'a_65', 'a_43'}],\n",
       "       [{'a_78', 'a_83'}]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "correlation_threshold = 0.9 # can be switched. Default value 0.99\n",
    "\n",
    "train_integer = train_df.drop('label',axis=1)\n",
    "\n",
    "cor = train_integer.corr()\n",
    "cor.loc[:,:] =  np.tril(cor, k=-1)\n",
    "cor = cor.stack()\n",
    "correlated = cor[cor > correlation_threshold].reset_index().loc[:,['level_0','level_1']]\n",
    "correlated = correlated.query('level_0 not in level_1')\n",
    "correlated_array =  correlated.groupby('level_0').agg(lambda x: set(chain(x.level_0,x.level_1))).values\n",
    "correlated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a_18', 'a_19', 'a_24', 'a_26', 'a_31', 'a_32', 'a_35', 'a_37', 'a_43', 'a_45', 'a_48', 'a_49', 'a_52', 'a_53', 'a_54', 'a_55', 'a_56', 'a_60', 'a_61', 'a_62', 'a_64', 'a_65', 'a_69', 'a_71', 'a_75', 'a_76', 'a_77', 'a_83']\n"
     ]
    }
   ],
   "source": [
    "correlated_features = []\n",
    "for sets in correlated_array:\n",
    "    element_list = list(sets[0])\n",
    "    for idx, el in enumerate(element_list):\n",
    "        if idx is not 0:\n",
    "            correlated_features.append(el)\n",
    "correlated_features.sort(key = lambda x: int(x[2:]) )\n",
    "print (correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 70)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_cor_train_df = train_df.drop(correlated_features, axis=1 )\n",
    "non_cor_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_non_cor = list(non_cor_train_df.columns)\n",
    "features_non_cor.remove(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 69)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_cor = non_cor_train_df[features_non_cor].values\n",
    "X_non_cor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_non_cor = non_cor_train_df[\"label\"].values\n",
    "Y_non_cor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_non_cor_train, X_non_cor_test, Y_non_cor_train, Y_non_cor_test = \\\n",
    "train_test_split (X_non_cor, Y_non_cor, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([398592,   1408]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_non_cor_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([99683,   317]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_non_cor_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we will try oversampling of minority class, undersampling of majority class for handling data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000, 69), (400000,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_cor_train.shape, Y_non_cor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "X_non_cor_full = pd.concat([pd.DataFrame(X_non_cor_train, columns=non_cor_train_df.columns.drop('label')), \n",
    "                            pd.DataFrame(Y_non_cor_train, columns=['label'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_0</th>\n",
       "      <th>a_1</th>\n",
       "      <th>a_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>a_5</th>\n",
       "      <th>a_6</th>\n",
       "      <th>a_7</th>\n",
       "      <th>a_8</th>\n",
       "      <th>a_16</th>\n",
       "      <th>a_17</th>\n",
       "      <th>a_20</th>\n",
       "      <th>a_21</th>\n",
       "      <th>a_22</th>\n",
       "      <th>a_23</th>\n",
       "      <th>a_25</th>\n",
       "      <th>a_27</th>\n",
       "      <th>a_28</th>\n",
       "      <th>a_29</th>\n",
       "      <th>a_30</th>\n",
       "      <th>a_33</th>\n",
       "      <th>a_34</th>\n",
       "      <th>a_36</th>\n",
       "      <th>a_38</th>\n",
       "      <th>a_39</th>\n",
       "      <th>a_40</th>\n",
       "      <th>a_41</th>\n",
       "      <th>a_42</th>\n",
       "      <th>a_44</th>\n",
       "      <th>a_46</th>\n",
       "      <th>a_47</th>\n",
       "      <th>a_50</th>\n",
       "      <th>a_51</th>\n",
       "      <th>a_57</th>\n",
       "      <th>a_58</th>\n",
       "      <th>a_59</th>\n",
       "      <th>a_63</th>\n",
       "      <th>a_66</th>\n",
       "      <th>a_67</th>\n",
       "      <th>a_68</th>\n",
       "      <th>a_70</th>\n",
       "      <th>a_72</th>\n",
       "      <th>a_73</th>\n",
       "      <th>a_74</th>\n",
       "      <th>a_78</th>\n",
       "      <th>a_79</th>\n",
       "      <th>a_80</th>\n",
       "      <th>a_81</th>\n",
       "      <th>a_82</th>\n",
       "      <th>a_84</th>\n",
       "      <th>a_9</th>\n",
       "      <th>a_10</th>\n",
       "      <th>a_11</th>\n",
       "      <th>a_12</th>\n",
       "      <th>a_13</th>\n",
       "      <th>a_14</th>\n",
       "      <th>a_15</th>\n",
       "      <th>a_85</th>\n",
       "      <th>a_86_id</th>\n",
       "      <th>a_86_ie</th>\n",
       "      <th>a_86_mc</th>\n",
       "      <th>a_86_or</th>\n",
       "      <th>a_86_tt</th>\n",
       "      <th>a_86_ws</th>\n",
       "      <th>a_87_dy</th>\n",
       "      <th>a_87_el</th>\n",
       "      <th>a_87_oc</th>\n",
       "      <th>a_87_or</th>\n",
       "      <th>a_87_sm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327816</th>\n",
       "      <td>4044.0</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.149433</td>\n",
       "      <td>0.050061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.114467</td>\n",
       "      <td>0.423143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.146117</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150140</th>\n",
       "      <td>4044.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.123033</td>\n",
       "      <td>9.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.441350</td>\n",
       "      <td>19.220925</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.441350</td>\n",
       "      <td>19.220925</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.325933</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245814</th>\n",
       "      <td>4044.0</td>\n",
       "      <td>179.00</td>\n",
       "      <td>4.1598</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.999090</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.849317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.488150</td>\n",
       "      <td>1.244325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.001150</td>\n",
       "      <td>1.000633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.603633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182323</th>\n",
       "      <td>4044.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.240783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.240783</td>\n",
       "      <td>33.120642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.240783</td>\n",
       "      <td>33.120642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.240783</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153624</th>\n",
       "      <td>4125.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.065799</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.399900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.399900</td>\n",
       "      <td>3.700200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.399900</td>\n",
       "      <td>3.700200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.399900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           a_0     a_1     a_2    a_3       a_4       a_5  a_6  a_7  a_8  \\\n",
       "327816  4044.0   12.99  0.0000    0.0  0.000000  0.013924  1.0  2.0  0.0   \n",
       "150140  4044.0    9.45  0.0000    0.0  0.000000  0.000455  2.0  2.0  0.0   \n",
       "245814  4044.0  179.00  4.1598  170.0  0.012872  0.999090  5.0  2.0  0.0   \n",
       "182323  4044.0    3.99  0.0000    0.0  0.000000  0.000273  1.0  2.0  0.0   \n",
       "153624  4125.0   17.00  5.0000    2.0  0.010554  0.065799  2.0  2.0  0.0   \n",
       "\n",
       "        a_16  a_17  a_20  a_21  a_22       a_23  a_25  a_27  a_28  a_29  a_30  \\\n",
       "327816   1.0   1.0  14.0   2.0   0.0   0.000000   1.0   0.0   0.0   1.0   1.0   \n",
       "150140   9.0  15.0  18.0   2.0   4.0  26.123033   9.0  82.0   0.0   1.0   5.0   \n",
       "245814   0.0   2.0  11.0   2.0   2.0   1.849317   0.0   0.0   0.0   4.0   0.0   \n",
       "182323   5.0  23.0  14.0   2.0  16.0  66.240783   1.0  11.0   0.0   3.0   1.0   \n",
       "153624   6.0   8.0   8.0   2.0   0.0   7.399900   5.0   0.0   0.0   1.0   5.0   \n",
       "\n",
       "        a_33  a_34  a_36  a_38  a_39       a_40       a_41  a_42  a_44  a_46  \\\n",
       "327816   0.0   3.0   4.0   0.0   2.0   0.149433   0.050061   2.0  32.0   1.0   \n",
       "150140   0.0   2.0  17.0   0.0   4.0  38.441350  19.220925  11.0  82.0   1.0   \n",
       "245814   0.0   2.0   6.0   0.0   5.0   2.488150   1.244325   0.0   0.0   4.0   \n",
       "182323   0.0   2.0  24.0   0.0  16.0  66.240783  33.120642   1.0  11.0   3.0   \n",
       "153624   0.0   2.0   9.0   0.0   0.0   7.399900   3.700200   5.0   0.0   1.0   \n",
       "\n",
       "        a_47  a_50  a_51       a_57       a_58  a_59  a_63  a_66  a_67  a_68  \\\n",
       "327816   1.0   0.0   5.0   2.114467   0.423143   4.0   1.0  18.0   0.0   8.0   \n",
       "150140   5.0   0.0   2.0  38.441350  19.220925  11.0   1.0  40.0   0.0   6.0   \n",
       "245814   0.0   0.0   3.0   3.001150   1.000633   0.0   4.0   0.0   0.0   4.0   \n",
       "182323   1.0   0.0   2.0  66.240783  33.120642   1.0   3.0   2.0   0.0   2.0   \n",
       "153624   5.0   0.0   2.0   7.399900   3.700200   5.0   1.0   0.0   0.0   2.0   \n",
       "\n",
       "        a_70  a_72  a_73       a_74    a_78  a_79  a_80  a_81  a_82  a_84  \\\n",
       "327816  87.0   4.0  37.0  76.146117  1282.0   1.0   1.0  16.0   1.0   1.0   \n",
       "150140  33.0   3.0   5.0  46.325933    82.0   0.0   1.0   5.0   0.0   0.0   \n",
       "245814  12.0   0.0   8.0   4.603633     0.0   0.0   4.0   0.0   0.0   0.0   \n",
       "182323  24.0   0.0  16.0  66.240783    11.0   0.0   3.0   1.0   0.0   0.0   \n",
       "153624   9.0   0.0   0.0   7.399900     0.0   0.0   1.0   5.0   0.0   0.0   \n",
       "\n",
       "        a_9  a_10  a_11  a_12  a_13  a_14  a_15  a_85  a_86_id  a_86_ie  \\\n",
       "327816  0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0      0.0      0.0   \n",
       "150140  0.0   1.0   0.0   0.0   0.0   1.0   1.0   0.0      0.0      1.0   \n",
       "245814  0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0      0.0      1.0   \n",
       "182323  0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0      0.0      0.0   \n",
       "153624  0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0      0.0      0.0   \n",
       "\n",
       "        a_86_mc  a_86_or  a_86_tt  a_86_ws  a_87_dy  a_87_el  a_87_oc  \\\n",
       "327816      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "150140      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "245814      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "182323      0.0      1.0      0.0      0.0      0.0      0.0      1.0   \n",
       "153624      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "        a_87_or  a_87_sm  label  \n",
       "327816      0.0      0.0      0  \n",
       "150140      0.0      0.0      0  \n",
       "245814      0.0      0.0      0  \n",
       "182323      0.0      0.0      0  \n",
       "153624      0.0      0.0      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_cor_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_majority = X_non_cor_full[X_non_cor_full['label']==0]\n",
    "class_minority = X_non_cor_full[X_non_cor_full['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_upsampled = resample(class_minority,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(class_majority), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([class_majority, minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    398592\n",
       "0    398592\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_upsampled = upsampled.label\n",
    "X_train_upsampled = upsampled.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797184, 69) (797184,) Index(['a_0', 'a_1', 'a_2', 'a_3', 'a_4', 'a_5', 'a_6', 'a_7', 'a_8', 'a_16',\n",
      "       'a_17', 'a_20', 'a_21', 'a_22', 'a_23', 'a_25', 'a_27', 'a_28', 'a_29',\n",
      "       'a_30', 'a_33', 'a_34', 'a_36', 'a_38', 'a_39', 'a_40', 'a_41', 'a_42',\n",
      "       'a_44', 'a_46', 'a_47', 'a_50', 'a_51', 'a_57', 'a_58', 'a_59', 'a_63',\n",
      "       'a_66', 'a_67', 'a_68', 'a_70', 'a_72', 'a_73', 'a_74', 'a_78', 'a_79',\n",
      "       'a_80', 'a_81', 'a_82', 'a_84', 'a_9', 'a_10', 'a_11', 'a_12', 'a_13',\n",
      "       'a_14', 'a_15', 'a_85', 'a_86_id', 'a_86_ie', 'a_86_mc', 'a_86_or',\n",
      "       'a_86_tt', 'a_86_ws', 'a_87_dy', 'a_87_el', 'a_87_oc', 'a_87_or',\n",
      "       'a_87_sm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_upsampled.shape, Y_train_upsampled.shape, X_train_upsampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-aa7284bb0a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_non_cor_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_non_cor_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_non_cor_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "X_non_cor_test.shape, Y_non_cor_test.shape, X_non_cor_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train_upsampled, Y_train_upsampled)\n",
    "upsampled_pred = upsampled.predict(X_non_cor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58104 0.6876971608832808 0.005188623110793764 0.010299536993291128\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_non_cor_test, upsampled_pred), recall_score(Y_non_cor_test, upsampled_pred),\n",
    "precision_score(Y_non_cor_test, upsampled_pred), f1_score(Y_non_cor_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57886, 41797],\n",
       "       [   99,   218]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_non_cor_test, upsampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.04400000e+03, 7.49600000e+01, 4.07140000e+00, 1.40000000e+01,\n",
       "       0.00000000e+00, 7.16235894e-02, 4.00000000e+00, 2.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       2.00000000e+00, 0.00000000e+00, 6.61833333e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.61833333e-02, 6.64333333e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.00000000e+00, 6.61833333e-02, 6.64333333e-02, 0.00000000e+00,\n",
       "       4.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.00000000e+00,\n",
       "       1.70000000e+01, 0.00000000e+00, 9.00000000e+00, 2.06467000e+01,\n",
       "       2.00000000e+00, 0.00000000e+00, 3.00000000e+00, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_cor_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_non_cor_test_1 = pd.DataFrame(X_non_cor_test, columns=non_cor_train_df.columns.drop('label')) \n",
    "Y_non_cor_test_1 = pd.DataFrame(Y_non_cor_test, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshav.somani/.py_venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.22613\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.17699\n",
      "[2]\tvalidation_0-error:0.17638\n",
      "[3]\tvalidation_0-error:0.17103\n",
      "[4]\tvalidation_0-error:0.15839\n",
      "[5]\tvalidation_0-error:0.15626\n",
      "[6]\tvalidation_0-error:0.14961\n",
      "[7]\tvalidation_0-error:0.14594\n",
      "[8]\tvalidation_0-error:0.1423\n",
      "[9]\tvalidation_0-error:0.14054\n",
      "[10]\tvalidation_0-error:0.13872\n",
      "[11]\tvalidation_0-error:0.13523\n",
      "[12]\tvalidation_0-error:0.13423\n",
      "[13]\tvalidation_0-error:0.13081\n",
      "[14]\tvalidation_0-error:0.1283\n",
      "[15]\tvalidation_0-error:0.12455\n",
      "[16]\tvalidation_0-error:0.12237\n",
      "[17]\tvalidation_0-error:0.11899\n",
      "[18]\tvalidation_0-error:0.11789\n",
      "[19]\tvalidation_0-error:0.11618\n",
      "[20]\tvalidation_0-error:0.11411\n",
      "[21]\tvalidation_0-error:0.11185\n",
      "[22]\tvalidation_0-error:0.10915\n",
      "[23]\tvalidation_0-error:0.10644\n",
      "[24]\tvalidation_0-error:0.10567\n",
      "[25]\tvalidation_0-error:0.10411\n",
      "[26]\tvalidation_0-error:0.10375\n",
      "[27]\tvalidation_0-error:0.10329\n",
      "[28]\tvalidation_0-error:0.10074\n",
      "[29]\tvalidation_0-error:0.09947\n",
      "[30]\tvalidation_0-error:0.09842\n",
      "[31]\tvalidation_0-error:0.09735\n",
      "[32]\tvalidation_0-error:0.0949\n",
      "[33]\tvalidation_0-error:0.09276\n",
      "[34]\tvalidation_0-error:0.09104\n",
      "[35]\tvalidation_0-error:0.09031\n",
      "[36]\tvalidation_0-error:0.08787\n",
      "[37]\tvalidation_0-error:0.0867\n",
      "[38]\tvalidation_0-error:0.08615\n",
      "[39]\tvalidation_0-error:0.0845\n",
      "[40]\tvalidation_0-error:0.08298\n",
      "[41]\tvalidation_0-error:0.08186\n",
      "[42]\tvalidation_0-error:0.0805\n",
      "[43]\tvalidation_0-error:0.08008\n",
      "[44]\tvalidation_0-error:0.07979\n",
      "[45]\tvalidation_0-error:0.07878\n",
      "[46]\tvalidation_0-error:0.07746\n",
      "[47]\tvalidation_0-error:0.07654\n",
      "[48]\tvalidation_0-error:0.07603\n",
      "[49]\tvalidation_0-error:0.0752\n",
      "[50]\tvalidation_0-error:0.07502\n",
      "[51]\tvalidation_0-error:0.07295\n",
      "[52]\tvalidation_0-error:0.07137\n",
      "[53]\tvalidation_0-error:0.06998\n",
      "[54]\tvalidation_0-error:0.06917\n",
      "[55]\tvalidation_0-error:0.06806\n",
      "[56]\tvalidation_0-error:0.06715\n",
      "[57]\tvalidation_0-error:0.06651\n",
      "[58]\tvalidation_0-error:0.06604\n",
      "[59]\tvalidation_0-error:0.06528\n",
      "[60]\tvalidation_0-error:0.06365\n",
      "[61]\tvalidation_0-error:0.06321\n",
      "[62]\tvalidation_0-error:0.06231\n",
      "[63]\tvalidation_0-error:0.06118\n",
      "[64]\tvalidation_0-error:0.0606\n",
      "[65]\tvalidation_0-error:0.06016\n",
      "[66]\tvalidation_0-error:0.05891\n",
      "[67]\tvalidation_0-error:0.05821\n",
      "[68]\tvalidation_0-error:0.05777\n",
      "[69]\tvalidation_0-error:0.05702\n",
      "[70]\tvalidation_0-error:0.05647\n",
      "[71]\tvalidation_0-error:0.05584\n",
      "[72]\tvalidation_0-error:0.05524\n",
      "[73]\tvalidation_0-error:0.05491\n",
      "[74]\tvalidation_0-error:0.05364\n",
      "[75]\tvalidation_0-error:0.05291\n",
      "[76]\tvalidation_0-error:0.05231\n",
      "[77]\tvalidation_0-error:0.0517\n",
      "[78]\tvalidation_0-error:0.05133\n",
      "[79]\tvalidation_0-error:0.0507\n",
      "[80]\tvalidation_0-error:0.05\n",
      "[81]\tvalidation_0-error:0.04952\n",
      "[82]\tvalidation_0-error:0.04817\n",
      "[83]\tvalidation_0-error:0.04793\n",
      "[84]\tvalidation_0-error:0.04713\n",
      "[85]\tvalidation_0-error:0.04655\n",
      "[86]\tvalidation_0-error:0.04612\n",
      "[87]\tvalidation_0-error:0.04576\n",
      "[88]\tvalidation_0-error:0.04461\n",
      "[89]\tvalidation_0-error:0.04428\n",
      "[90]\tvalidation_0-error:0.04425\n",
      "[91]\tvalidation_0-error:0.04382\n",
      "[92]\tvalidation_0-error:0.04271\n",
      "[93]\tvalidation_0-error:0.04204\n",
      "[94]\tvalidation_0-error:0.0414\n",
      "[95]\tvalidation_0-error:0.04083\n",
      "[96]\tvalidation_0-error:0.03982\n",
      "[97]\tvalidation_0-error:0.03939\n",
      "[98]\tvalidation_0-error:0.03872\n",
      "[99]\tvalidation_0-error:0.03765\n",
      "[100]\tvalidation_0-error:0.03735\n",
      "[101]\tvalidation_0-error:0.03697\n",
      "[102]\tvalidation_0-error:0.03688\n",
      "[103]\tvalidation_0-error:0.03654\n",
      "[104]\tvalidation_0-error:0.03581\n",
      "[105]\tvalidation_0-error:0.03513\n",
      "[106]\tvalidation_0-error:0.0345\n",
      "[107]\tvalidation_0-error:0.03381\n",
      "[108]\tvalidation_0-error:0.03377\n",
      "[109]\tvalidation_0-error:0.03338\n",
      "[110]\tvalidation_0-error:0.03295\n",
      "[111]\tvalidation_0-error:0.03271\n",
      "[112]\tvalidation_0-error:0.03249\n",
      "[113]\tvalidation_0-error:0.03229\n",
      "[114]\tvalidation_0-error:0.03204\n",
      "[115]\tvalidation_0-error:0.03176\n",
      "[116]\tvalidation_0-error:0.03137\n",
      "[117]\tvalidation_0-error:0.03126\n",
      "[118]\tvalidation_0-error:0.03113\n",
      "[119]\tvalidation_0-error:0.031\n",
      "[120]\tvalidation_0-error:0.03034\n",
      "[121]\tvalidation_0-error:0.0299\n",
      "[122]\tvalidation_0-error:0.02964\n",
      "[123]\tvalidation_0-error:0.02935\n",
      "[124]\tvalidation_0-error:0.0292\n",
      "[125]\tvalidation_0-error:0.02898\n",
      "[126]\tvalidation_0-error:0.0289\n",
      "[127]\tvalidation_0-error:0.02857\n",
      "[128]\tvalidation_0-error:0.02834\n",
      "[129]\tvalidation_0-error:0.02765\n",
      "[130]\tvalidation_0-error:0.02767\n",
      "[131]\tvalidation_0-error:0.0273\n",
      "[132]\tvalidation_0-error:0.02677\n",
      "[133]\tvalidation_0-error:0.02635\n",
      "[134]\tvalidation_0-error:0.026\n",
      "[135]\tvalidation_0-error:0.0259\n",
      "[136]\tvalidation_0-error:0.02568\n",
      "[137]\tvalidation_0-error:0.02542\n",
      "[138]\tvalidation_0-error:0.02494\n",
      "[139]\tvalidation_0-error:0.02488\n",
      "[140]\tvalidation_0-error:0.02469\n",
      "[141]\tvalidation_0-error:0.02453\n",
      "[142]\tvalidation_0-error:0.02425\n",
      "[143]\tvalidation_0-error:0.02418\n",
      "[144]\tvalidation_0-error:0.02403\n",
      "[145]\tvalidation_0-error:0.02348\n",
      "[146]\tvalidation_0-error:0.02318\n",
      "[147]\tvalidation_0-error:0.02295\n",
      "[148]\tvalidation_0-error:0.02262\n",
      "[149]\tvalidation_0-error:0.02224\n",
      "[150]\tvalidation_0-error:0.02203\n",
      "[151]\tvalidation_0-error:0.02182\n",
      "[152]\tvalidation_0-error:0.02169\n",
      "[153]\tvalidation_0-error:0.0215\n",
      "[154]\tvalidation_0-error:0.02136\n",
      "[155]\tvalidation_0-error:0.02113\n",
      "[156]\tvalidation_0-error:0.02096\n",
      "[157]\tvalidation_0-error:0.02079\n",
      "[158]\tvalidation_0-error:0.02048\n",
      "[159]\tvalidation_0-error:0.02047\n",
      "[160]\tvalidation_0-error:0.02006\n",
      "[161]\tvalidation_0-error:0.01971\n",
      "[162]\tvalidation_0-error:0.01948\n",
      "[163]\tvalidation_0-error:0.01939\n",
      "[164]\tvalidation_0-error:0.01909\n",
      "[165]\tvalidation_0-error:0.01887\n",
      "[166]\tvalidation_0-error:0.01846\n",
      "[167]\tvalidation_0-error:0.01818\n",
      "[168]\tvalidation_0-error:0.01809\n",
      "[169]\tvalidation_0-error:0.01799\n",
      "[170]\tvalidation_0-error:0.01782\n",
      "[171]\tvalidation_0-error:0.01764\n",
      "[172]\tvalidation_0-error:0.01749\n",
      "[173]\tvalidation_0-error:0.01728\n",
      "[174]\tvalidation_0-error:0.01719\n",
      "[175]\tvalidation_0-error:0.01702\n",
      "[176]\tvalidation_0-error:0.01699\n",
      "[177]\tvalidation_0-error:0.0169\n",
      "[178]\tvalidation_0-error:0.01688\n",
      "[179]\tvalidation_0-error:0.0168\n",
      "[180]\tvalidation_0-error:0.0167\n",
      "[181]\tvalidation_0-error:0.01665\n",
      "[182]\tvalidation_0-error:0.01656\n",
      "[183]\tvalidation_0-error:0.01649\n",
      "[184]\tvalidation_0-error:0.01624\n",
      "[185]\tvalidation_0-error:0.01619\n",
      "[186]\tvalidation_0-error:0.01601\n",
      "[187]\tvalidation_0-error:0.01588\n",
      "[188]\tvalidation_0-error:0.0156\n",
      "[189]\tvalidation_0-error:0.01547\n",
      "[190]\tvalidation_0-error:0.01543\n",
      "[191]\tvalidation_0-error:0.0154\n",
      "[192]\tvalidation_0-error:0.01534\n",
      "[193]\tvalidation_0-error:0.01507\n",
      "[194]\tvalidation_0-error:0.01506\n",
      "[195]\tvalidation_0-error:0.015\n",
      "[196]\tvalidation_0-error:0.01488\n",
      "[197]\tvalidation_0-error:0.01477\n",
      "[198]\tvalidation_0-error:0.01446\n",
      "[199]\tvalidation_0-error:0.01414\n",
      "[200]\tvalidation_0-error:0.01404\n",
      "[201]\tvalidation_0-error:0.01399\n",
      "[202]\tvalidation_0-error:0.01387\n",
      "[203]\tvalidation_0-error:0.01368\n",
      "[204]\tvalidation_0-error:0.01339\n",
      "[205]\tvalidation_0-error:0.01338\n",
      "[206]\tvalidation_0-error:0.01321\n",
      "[207]\tvalidation_0-error:0.01312\n",
      "[208]\tvalidation_0-error:0.01306\n",
      "[209]\tvalidation_0-error:0.01291\n",
      "[210]\tvalidation_0-error:0.0129\n",
      "[211]\tvalidation_0-error:0.01277\n",
      "[212]\tvalidation_0-error:0.01275\n",
      "[213]\tvalidation_0-error:0.01247\n",
      "[214]\tvalidation_0-error:0.01236\n",
      "[215]\tvalidation_0-error:0.01235\n",
      "[216]\tvalidation_0-error:0.0124\n",
      "[217]\tvalidation_0-error:0.01235\n",
      "[218]\tvalidation_0-error:0.01224\n",
      "[219]\tvalidation_0-error:0.01219\n",
      "[220]\tvalidation_0-error:0.01213\n",
      "[221]\tvalidation_0-error:0.01196\n",
      "[222]\tvalidation_0-error:0.01191\n",
      "[223]\tvalidation_0-error:0.01186\n",
      "[224]\tvalidation_0-error:0.01188\n",
      "[225]\tvalidation_0-error:0.01181\n",
      "[226]\tvalidation_0-error:0.0117\n",
      "[227]\tvalidation_0-error:0.01166\n",
      "[228]\tvalidation_0-error:0.01158\n",
      "[229]\tvalidation_0-error:0.01151\n",
      "[230]\tvalidation_0-error:0.01139\n",
      "[231]\tvalidation_0-error:0.01125\n",
      "[232]\tvalidation_0-error:0.01106\n",
      "[233]\tvalidation_0-error:0.01084\n",
      "[234]\tvalidation_0-error:0.01082\n",
      "[235]\tvalidation_0-error:0.01075\n",
      "[236]\tvalidation_0-error:0.01071\n",
      "[237]\tvalidation_0-error:0.01067\n",
      "[238]\tvalidation_0-error:0.01066\n",
      "[239]\tvalidation_0-error:0.01063\n",
      "[240]\tvalidation_0-error:0.01061\n",
      "[241]\tvalidation_0-error:0.01054\n",
      "[242]\tvalidation_0-error:0.01043\n",
      "[243]\tvalidation_0-error:0.01034\n",
      "[244]\tvalidation_0-error:0.01029\n",
      "[245]\tvalidation_0-error:0.01019\n",
      "[246]\tvalidation_0-error:0.01013\n",
      "[247]\tvalidation_0-error:0.01002\n",
      "[248]\tvalidation_0-error:0.00998\n",
      "[249]\tvalidation_0-error:0.00989\n",
      "[250]\tvalidation_0-error:0.00973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251]\tvalidation_0-error:0.00971\n",
      "[252]\tvalidation_0-error:0.00971\n",
      "[253]\tvalidation_0-error:0.00969\n",
      "[254]\tvalidation_0-error:0.0096\n",
      "[255]\tvalidation_0-error:0.00954\n",
      "[256]\tvalidation_0-error:0.00942\n",
      "[257]\tvalidation_0-error:0.00927\n",
      "[258]\tvalidation_0-error:0.00925\n",
      "[259]\tvalidation_0-error:0.00924\n",
      "[260]\tvalidation_0-error:0.00917\n",
      "[261]\tvalidation_0-error:0.00908\n",
      "[262]\tvalidation_0-error:0.00899\n",
      "[263]\tvalidation_0-error:0.00885\n",
      "[264]\tvalidation_0-error:0.00891\n",
      "[265]\tvalidation_0-error:0.00882\n",
      "[266]\tvalidation_0-error:0.00877\n",
      "[267]\tvalidation_0-error:0.00871\n",
      "[268]\tvalidation_0-error:0.0087\n",
      "[269]\tvalidation_0-error:0.00865\n",
      "[270]\tvalidation_0-error:0.00858\n",
      "[271]\tvalidation_0-error:0.00844\n",
      "[272]\tvalidation_0-error:0.00839\n",
      "[273]\tvalidation_0-error:0.00826\n",
      "[274]\tvalidation_0-error:0.0082\n",
      "[275]\tvalidation_0-error:0.00814\n",
      "[276]\tvalidation_0-error:0.0081\n",
      "[277]\tvalidation_0-error:0.00809\n",
      "[278]\tvalidation_0-error:0.00806\n",
      "[279]\tvalidation_0-error:0.00803\n",
      "[280]\tvalidation_0-error:0.00799\n",
      "[281]\tvalidation_0-error:0.00793\n",
      "[282]\tvalidation_0-error:0.00788\n",
      "[283]\tvalidation_0-error:0.00785\n",
      "[284]\tvalidation_0-error:0.00783\n",
      "[285]\tvalidation_0-error:0.00784\n",
      "[286]\tvalidation_0-error:0.00777\n",
      "[287]\tvalidation_0-error:0.00776\n",
      "[288]\tvalidation_0-error:0.00771\n",
      "[289]\tvalidation_0-error:0.00764\n",
      "[290]\tvalidation_0-error:0.00759\n",
      "[291]\tvalidation_0-error:0.00755\n",
      "[292]\tvalidation_0-error:0.00747\n",
      "[293]\tvalidation_0-error:0.00741\n",
      "[294]\tvalidation_0-error:0.00732\n",
      "[295]\tvalidation_0-error:0.00735\n",
      "[296]\tvalidation_0-error:0.00726\n",
      "[297]\tvalidation_0-error:0.00718\n",
      "[298]\tvalidation_0-error:0.00715\n",
      "[299]\tvalidation_0-error:0.00707\n",
      "[300]\tvalidation_0-error:0.00697\n",
      "[301]\tvalidation_0-error:0.00695\n",
      "[302]\tvalidation_0-error:0.00694\n",
      "[303]\tvalidation_0-error:0.00688\n",
      "[304]\tvalidation_0-error:0.00688\n",
      "[305]\tvalidation_0-error:0.00684\n",
      "[306]\tvalidation_0-error:0.00682\n",
      "[307]\tvalidation_0-error:0.00683\n",
      "[308]\tvalidation_0-error:0.00681\n",
      "[309]\tvalidation_0-error:0.00677\n",
      "[310]\tvalidation_0-error:0.00673\n",
      "[311]\tvalidation_0-error:0.00669\n",
      "[312]\tvalidation_0-error:0.00665\n",
      "[313]\tvalidation_0-error:0.00662\n",
      "[314]\tvalidation_0-error:0.00657\n",
      "[315]\tvalidation_0-error:0.00656\n",
      "[316]\tvalidation_0-error:0.00656\n",
      "[317]\tvalidation_0-error:0.00648\n",
      "[318]\tvalidation_0-error:0.00637\n",
      "[319]\tvalidation_0-error:0.00637\n",
      "[320]\tvalidation_0-error:0.0063\n",
      "[321]\tvalidation_0-error:0.0063\n",
      "[322]\tvalidation_0-error:0.00628\n",
      "[323]\tvalidation_0-error:0.00619\n",
      "[324]\tvalidation_0-error:0.00617\n",
      "[325]\tvalidation_0-error:0.00617\n",
      "[326]\tvalidation_0-error:0.00612\n",
      "[327]\tvalidation_0-error:0.00608\n",
      "[328]\tvalidation_0-error:0.0061\n",
      "[329]\tvalidation_0-error:0.00608\n",
      "[330]\tvalidation_0-error:0.00597\n",
      "[331]\tvalidation_0-error:0.00596\n",
      "[332]\tvalidation_0-error:0.00593\n",
      "[333]\tvalidation_0-error:0.00585\n",
      "[334]\tvalidation_0-error:0.00585\n",
      "[335]\tvalidation_0-error:0.00588\n",
      "[336]\tvalidation_0-error:0.00586\n",
      "[337]\tvalidation_0-error:0.00582\n",
      "[338]\tvalidation_0-error:0.0058\n",
      "[339]\tvalidation_0-error:0.0058\n",
      "[340]\tvalidation_0-error:0.0058\n",
      "[341]\tvalidation_0-error:0.00576\n",
      "[342]\tvalidation_0-error:0.00577\n",
      "[343]\tvalidation_0-error:0.00573\n",
      "[344]\tvalidation_0-error:0.0057\n",
      "[345]\tvalidation_0-error:0.00571\n",
      "[346]\tvalidation_0-error:0.0057\n",
      "[347]\tvalidation_0-error:0.0057\n",
      "[348]\tvalidation_0-error:0.00566\n",
      "[349]\tvalidation_0-error:0.00564\n",
      "[350]\tvalidation_0-error:0.00562\n",
      "[351]\tvalidation_0-error:0.00558\n",
      "[352]\tvalidation_0-error:0.00557\n",
      "[353]\tvalidation_0-error:0.00552\n",
      "[354]\tvalidation_0-error:0.00544\n",
      "[355]\tvalidation_0-error:0.00545\n",
      "[356]\tvalidation_0-error:0.00545\n",
      "[357]\tvalidation_0-error:0.00541\n",
      "[358]\tvalidation_0-error:0.00533\n",
      "[359]\tvalidation_0-error:0.00533\n",
      "[360]\tvalidation_0-error:0.00529\n",
      "[361]\tvalidation_0-error:0.00527\n",
      "[362]\tvalidation_0-error:0.00527\n",
      "[363]\tvalidation_0-error:0.00525\n",
      "[364]\tvalidation_0-error:0.00525\n",
      "[365]\tvalidation_0-error:0.0052\n",
      "[366]\tvalidation_0-error:0.00518\n",
      "[367]\tvalidation_0-error:0.00518\n",
      "[368]\tvalidation_0-error:0.00516\n",
      "[369]\tvalidation_0-error:0.00512\n",
      "[370]\tvalidation_0-error:0.00512\n",
      "[371]\tvalidation_0-error:0.00513\n",
      "[372]\tvalidation_0-error:0.00509\n",
      "[373]\tvalidation_0-error:0.00501\n",
      "[374]\tvalidation_0-error:0.00503\n",
      "[375]\tvalidation_0-error:0.005\n",
      "[376]\tvalidation_0-error:0.00501\n",
      "[377]\tvalidation_0-error:0.00501\n",
      "[378]\tvalidation_0-error:0.00499\n",
      "[379]\tvalidation_0-error:0.00493\n",
      "[380]\tvalidation_0-error:0.00493\n",
      "[381]\tvalidation_0-error:0.00492\n",
      "[382]\tvalidation_0-error:0.0049\n",
      "[383]\tvalidation_0-error:0.00489\n",
      "[384]\tvalidation_0-error:0.00488\n",
      "[385]\tvalidation_0-error:0.00489\n",
      "[386]\tvalidation_0-error:0.00488\n",
      "[387]\tvalidation_0-error:0.00487\n",
      "[388]\tvalidation_0-error:0.00486\n",
      "[389]\tvalidation_0-error:0.00486\n",
      "[390]\tvalidation_0-error:0.00482\n",
      "[391]\tvalidation_0-error:0.00486\n",
      "[392]\tvalidation_0-error:0.00484\n",
      "[393]\tvalidation_0-error:0.00482\n",
      "[394]\tvalidation_0-error:0.00484\n",
      "[395]\tvalidation_0-error:0.00483\n",
      "[396]\tvalidation_0-error:0.00478\n",
      "[397]\tvalidation_0-error:0.00477\n",
      "[398]\tvalidation_0-error:0.00477\n",
      "[399]\tvalidation_0-error:0.00478\n",
      "[400]\tvalidation_0-error:0.00481\n",
      "[401]\tvalidation_0-error:0.00477\n",
      "[402]\tvalidation_0-error:0.00476\n",
      "[403]\tvalidation_0-error:0.00479\n",
      "[404]\tvalidation_0-error:0.00478\n",
      "[405]\tvalidation_0-error:0.00479\n",
      "[406]\tvalidation_0-error:0.00474\n",
      "[407]\tvalidation_0-error:0.00473\n",
      "[408]\tvalidation_0-error:0.0047\n",
      "[409]\tvalidation_0-error:0.00467\n",
      "[410]\tvalidation_0-error:0.00467\n",
      "[411]\tvalidation_0-error:0.00465\n",
      "[412]\tvalidation_0-error:0.00464\n",
      "[413]\tvalidation_0-error:0.00464\n",
      "[414]\tvalidation_0-error:0.00462\n",
      "[415]\tvalidation_0-error:0.00462\n",
      "[416]\tvalidation_0-error:0.00457\n",
      "[417]\tvalidation_0-error:0.00456\n",
      "[418]\tvalidation_0-error:0.00456\n",
      "[419]\tvalidation_0-error:0.00456\n",
      "[420]\tvalidation_0-error:0.00454\n",
      "[421]\tvalidation_0-error:0.00448\n",
      "[422]\tvalidation_0-error:0.00444\n",
      "[423]\tvalidation_0-error:0.00441\n",
      "[424]\tvalidation_0-error:0.00438\n",
      "[425]\tvalidation_0-error:0.00437\n",
      "[426]\tvalidation_0-error:0.00436\n",
      "[427]\tvalidation_0-error:0.00437\n",
      "[428]\tvalidation_0-error:0.00437\n",
      "[429]\tvalidation_0-error:0.00435\n",
      "[430]\tvalidation_0-error:0.00433\n",
      "[431]\tvalidation_0-error:0.00434\n",
      "[432]\tvalidation_0-error:0.00433\n",
      "[433]\tvalidation_0-error:0.00432\n",
      "[434]\tvalidation_0-error:0.00433\n",
      "[435]\tvalidation_0-error:0.00434\n",
      "[436]\tvalidation_0-error:0.00433\n",
      "[437]\tvalidation_0-error:0.00432\n",
      "[438]\tvalidation_0-error:0.00432\n",
      "[439]\tvalidation_0-error:0.00432\n",
      "[440]\tvalidation_0-error:0.00432\n",
      "[441]\tvalidation_0-error:0.0043\n",
      "[442]\tvalidation_0-error:0.0043\n",
      "[443]\tvalidation_0-error:0.00428\n",
      "[444]\tvalidation_0-error:0.00427\n",
      "[445]\tvalidation_0-error:0.00421\n",
      "[446]\tvalidation_0-error:0.00422\n",
      "[447]\tvalidation_0-error:0.0042\n",
      "[448]\tvalidation_0-error:0.0042\n",
      "[449]\tvalidation_0-error:0.0042\n",
      "[450]\tvalidation_0-error:0.00422\n",
      "[451]\tvalidation_0-error:0.00422\n",
      "[452]\tvalidation_0-error:0.0042\n",
      "[453]\tvalidation_0-error:0.0042\n",
      "[454]\tvalidation_0-error:0.00419\n",
      "[455]\tvalidation_0-error:0.00419\n",
      "[456]\tvalidation_0-error:0.00418\n",
      "[457]\tvalidation_0-error:0.00417\n",
      "[458]\tvalidation_0-error:0.00418\n",
      "[459]\tvalidation_0-error:0.00418\n",
      "[460]\tvalidation_0-error:0.00418\n",
      "[461]\tvalidation_0-error:0.00417\n",
      "[462]\tvalidation_0-error:0.00415\n",
      "[463]\tvalidation_0-error:0.00415\n",
      "[464]\tvalidation_0-error:0.00414\n",
      "[465]\tvalidation_0-error:0.00413\n",
      "[466]\tvalidation_0-error:0.00414\n",
      "[467]\tvalidation_0-error:0.00412\n",
      "[468]\tvalidation_0-error:0.00414\n",
      "[469]\tvalidation_0-error:0.00414\n",
      "[470]\tvalidation_0-error:0.00414\n",
      "[471]\tvalidation_0-error:0.00413\n",
      "[472]\tvalidation_0-error:0.0041\n",
      "[473]\tvalidation_0-error:0.00411\n",
      "[474]\tvalidation_0-error:0.00409\n",
      "[475]\tvalidation_0-error:0.00408\n",
      "[476]\tvalidation_0-error:0.00408\n",
      "[477]\tvalidation_0-error:0.00409\n",
      "[478]\tvalidation_0-error:0.00408\n",
      "[479]\tvalidation_0-error:0.00407\n",
      "[480]\tvalidation_0-error:0.00409\n",
      "[481]\tvalidation_0-error:0.00407\n",
      "[482]\tvalidation_0-error:0.00405\n",
      "[483]\tvalidation_0-error:0.00405\n",
      "[484]\tvalidation_0-error:0.00403\n",
      "[485]\tvalidation_0-error:0.00402\n",
      "[486]\tvalidation_0-error:0.00401\n",
      "[487]\tvalidation_0-error:0.004\n",
      "[488]\tvalidation_0-error:0.00399\n",
      "[489]\tvalidation_0-error:0.004\n",
      "[490]\tvalidation_0-error:0.00397\n",
      "[491]\tvalidation_0-error:0.00399\n",
      "[492]\tvalidation_0-error:0.00401\n",
      "[493]\tvalidation_0-error:0.00399\n",
      "[494]\tvalidation_0-error:0.00397\n",
      "[495]\tvalidation_0-error:0.004\n",
      "[496]\tvalidation_0-error:0.00401\n",
      "[497]\tvalidation_0-error:0.00401\n",
      "[498]\tvalidation_0-error:0.00403\n",
      "[499]\tvalidation_0-error:0.00403\n",
      "[500]\tvalidation_0-error:0.00404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[490]\tvalidation_0-error:0.00397\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['a_0', 'a_1', 'a_2', 'a_3', 'a_4', 'a_5', 'a_6', 'a_7', 'a_8', 'a_16', 'a_17', 'a_20', 'a_21', 'a_22', 'a_23', 'a_25', 'a_27', 'a_28', 'a_29', 'a_30', 'a_33', 'a_34', 'a_36', 'a_38', 'a_39', 'a_40', 'a_41', 'a_42', 'a_44', 'a_46', 'a_47', 'a_50', 'a_51', 'a_57', 'a_58', 'a_59', 'a_63', 'a_66', 'a_67', 'a_68', 'a_70', 'a_72', 'a_73', 'a_74', 'a_78', 'a_79', 'a_80', 'a_81', 'a_82', 'a_84', 'a_9', 'a_10', 'a_11', 'a_12', 'a_13', 'a_14', 'a_15', 'a_85', 'a_86_id', 'a_86_ie', 'a_86_mc', 'a_86_or', 'a_86_tt', 'a_86_ws', 'a_87_dy', 'a_87_el', 'a_87_oc', 'a_87_or', 'a_87_sm'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68']\nexpected a_33, a_5, a_87_dy, a_8, a_86_id, a_59, a_86_ie, a_63, a_10, a_50, a_12, a_17, a_79, a_84, a_72, a_23, a_21, a_42, a_34, a_27, a_66, a_3, a_22, a_38, a_86_or, a_86_mc, a_20, a_78, a_81, a_9, a_57, a_44, a_6, a_86_tt, a_29, a_40, a_67, a_74, a_11, a_2, a_58, a_30, a_87_or, a_14, a_7, a_13, a_15, a_1, a_36, a_25, a_70, a_28, a_39, a_86_ws, a_73, a_87_el, a_41, a_4, a_85, a_82, a_87_oc, a_68, a_51, a_47, a_0, a_16, a_46, a_87_sm, a_80 in input data\ntraining data did not have the following fields: f7, f27, f31, f1, f20, f61, f25, f43, f66, f2, f4, f16, f44, f46, f64, f14, f18, f15, f52, f57, f19, f38, f40, f11, f12, f37, f65, f45, f56, f10, f67, f33, f36, f3, f0, f6, f41, f47, f39, f49, f50, f53, f8, f60, f58, f62, f30, f17, f51, f48, f24, f59, f32, f26, f5, f22, f42, f28, f9, f35, f34, f23, f63, f29, f54, f68, f21, f13, f55",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-80399d098316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# predicting the test set results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_xgbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_non_cor_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Calculating the accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.py_venv/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.py_venv/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.py_venv/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['a_0', 'a_1', 'a_2', 'a_3', 'a_4', 'a_5', 'a_6', 'a_7', 'a_8', 'a_16', 'a_17', 'a_20', 'a_21', 'a_22', 'a_23', 'a_25', 'a_27', 'a_28', 'a_29', 'a_30', 'a_33', 'a_34', 'a_36', 'a_38', 'a_39', 'a_40', 'a_41', 'a_42', 'a_44', 'a_46', 'a_47', 'a_50', 'a_51', 'a_57', 'a_58', 'a_59', 'a_63', 'a_66', 'a_67', 'a_68', 'a_70', 'a_72', 'a_73', 'a_74', 'a_78', 'a_79', 'a_80', 'a_81', 'a_82', 'a_84', 'a_9', 'a_10', 'a_11', 'a_12', 'a_13', 'a_14', 'a_15', 'a_85', 'a_86_id', 'a_86_ie', 'a_86_mc', 'a_86_or', 'a_86_tt', 'a_86_ws', 'a_87_dy', 'a_87_el', 'a_87_oc', 'a_87_or', 'a_87_sm'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68']\nexpected a_33, a_5, a_87_dy, a_8, a_86_id, a_59, a_86_ie, a_63, a_10, a_50, a_12, a_17, a_79, a_84, a_72, a_23, a_21, a_42, a_34, a_27, a_66, a_3, a_22, a_38, a_86_or, a_86_mc, a_20, a_78, a_81, a_9, a_57, a_44, a_6, a_86_tt, a_29, a_40, a_67, a_74, a_11, a_2, a_58, a_30, a_87_or, a_14, a_7, a_13, a_15, a_1, a_36, a_25, a_70, a_28, a_39, a_86_ws, a_73, a_87_el, a_41, a_4, a_85, a_82, a_87_oc, a_68, a_51, a_47, a_0, a_16, a_46, a_87_sm, a_80 in input data\ntraining data did not have the following fields: f7, f27, f31, f1, f20, f61, f25, f43, f66, f2, f4, f16, f44, f46, f64, f14, f18, f15, f52, f57, f19, f38, f40, f11, f12, f37, f65, f45, f56, f10, f67, f33, f36, f3, f0, f6, f41, f47, f39, f49, f50, f53, f8, f60, f58, f62, f30, f17, f51, f48, f24, f59, f32, f26, f5, f22, f42, f28, f9, f35, f34, f23, f63, f29, f54, f68, f21, f13, f55"
     ]
    }
   ],
   "source": [
    "eval_set = [(X_non_cor_test_1, Y_non_cor_test_1)]\n",
    "\n",
    "model_xgbs = xgb.XGBClassifier(gamma=0.024, learning_rate=0.3, \n",
    "                          max_depth=6,\n",
    "                          nthread=4,\n",
    "                          n_estimators=1000)\n",
    "\n",
    "model_xgbs.silent=False\n",
    "\n",
    "model_xgbs.fit(X_train_upsampled, Y_train_upsampled, early_stopping_rounds=10, \n",
    "          eval_set=eval_set,\n",
    "          verbose=True) #https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "# predicting the test set results\n",
    "Y_pred = model_xgbs.predict(X_non_cor_test_1)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model_xgbs.score(X_train_upsampled, Y_train_upsampled))\n",
    "print(\"Testing accuracy :\", model_xgbs.score(X_non_cor_test_1, Y_non_cor_test_1))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_non_cor_test_1, Y_pred))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_non_cor_test_1, Y_pred))\n",
    "print(precision_score(Y_non_cor_test_1, Y_pred))\n",
    "print(recall_score(Y_non_cor_test_1, Y_pred))\n",
    "print(accuracy_score(Y_non_cor_test_1, Y_pred))\n",
    "print(f1_score(Y_non_cor_test_1, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.999943551300578\n",
      "Testing accuracy : 0.99603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99683\n",
      "           1       0.16      0.06      0.08       317\n",
      "\n",
      "    accuracy                           1.00    100000\n",
      "   macro avg       0.58      0.53      0.54    100000\n",
      "weighted avg       0.99      1.00      1.00    100000\n",
      "\n",
      "[[99585    98]\n",
      " [  299    18]]\n",
      "0.15517241379310345\n",
      "0.056782334384858045\n",
      "0.99603\n",
      "0.08314087759815243\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.8169895532273603\n",
      "Testing accuracy : 0.82829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     99683\n",
      "           1       0.01      0.77      0.03       317\n",
      "\n",
      "    accuracy                           0.83    100000\n",
      "   macro avg       0.51      0.80      0.47    100000\n",
      "weighted avg       1.00      0.83      0.90    100000\n",
      "\n",
      "[[82584 17099]\n",
      " [   72   245]]\n",
      "0.82829\n",
      "0.014125922509225092\n",
      "0.7728706624605678\n",
      "0.027744748315497423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# creating the model\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# feeding the training data into the model\n",
    "model.fit(X_train_upsampled, Y_train_upsampled)\n",
    "\n",
    "# predicting the test set results\n",
    "y_pred_s = model.predict(X_non_cor_test_1)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model.score(X_train_upsampled, Y_train_upsampled))\n",
    "print(\"Testing accuracy :\", model.score(X_non_cor_test_1, Y_non_cor_test_1))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_non_cor_test_1, y_pred_s))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_non_cor_test_1, y_pred_s))\n",
    "print(accuracy_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(precision_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(recall_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(f1_score(Y_non_cor_test_1, y_pred_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.9999987455844573\n",
      "Testing accuracy : 0.99319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99683\n",
      "           1       0.01      0.02      0.01       317\n",
      "\n",
      "    accuracy                           0.99    100000\n",
      "   macro avg       0.51      0.51      0.51    100000\n",
      "weighted avg       0.99      0.99      0.99    100000\n",
      "\n",
      "[[99314   369]\n",
      " [  312     5]]\n",
      "0.99319\n",
      "0.013368983957219251\n",
      "0.015772870662460567\n",
      "0.014471780028943561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# creating the model\n",
    "model_s = DecisionTreeClassifier()\n",
    "\n",
    "# feeding the training data into the model\n",
    "model_s.fit(X_train_upsampled, Y_train_upsampled)\n",
    "\n",
    "# predicting the test set results\n",
    "y_pred_s = model_s.predict(X_non_cor_test_1)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model_s.score(X_train_upsampled, Y_train_upsampled))\n",
    "print(\"Testing accuracy :\", model_s.score(X_non_cor_test_1, Y_non_cor_test_1))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_non_cor_test_1, y_pred_s))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_non_cor_test_1, y_pred_s))\n",
    "print(accuracy_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(precision_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(recall_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(f1_score(Y_non_cor_test_1, y_pred_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshav.somani/.py_venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.9999974911689146\n",
      "Testing accuracy : 0.99686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99683\n",
      "           1       0.71      0.02      0.03       317\n",
      "\n",
      "    accuracy                           1.00    100000\n",
      "   macro avg       0.86      0.51      0.51    100000\n",
      "weighted avg       1.00      1.00      1.00    100000\n",
      "\n",
      "[[99681     2]\n",
      " [  312     5]]\n",
      "0.99686\n",
      "0.7142857142857143\n",
      "0.015772870662460567\n",
      "0.030864197530864192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# creating the model\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# feeding the training data into the model\n",
    "model_rf.fit(X_train_upsampled, Y_train_upsampled)\n",
    "\n",
    "# predicting the test set results\n",
    "y_pred_s = model_rf.predict(X_non_cor_test_1)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model_rf.score(X_train_upsampled, Y_train_upsampled))\n",
    "print(\"Testing accuracy :\", model_rf.score(X_non_cor_test_1, Y_non_cor_test_1))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_non_cor_test_1, y_pred_s))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_non_cor_test_1, y_pred_s))\n",
    "print(accuracy_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(precision_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(recall_score(Y_non_cor_test_1, y_pred_s))\n",
    "print(f1_score(Y_non_cor_test_1, y_pred_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_upsampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-42c333a53284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# feeding the training data into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_upsampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_upsampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# predicting the test set results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_upsampled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# creating the model\n",
    "model = SVC(gamma=\"auto\", kernel='rbf')\n",
    "\n",
    "# feeding the training data into the model\n",
    "model.fit(X_train_upsampled, Y_train_upsampled)\n",
    "\n",
    "# predicting the test set results\n",
    "y_pred_s = model.predict(X_non_cor_test_1)\n",
    "\n",
    "# Calculating the accuracies\n",
    "print(\"Training accuracy :\", model.score(X_train_upsampled, Y_train_upsampled))\n",
    "print(\"Testing accuracy :\", model.score(X_non_cor_test_1, Y_non_cor_test_1))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(Y_non_cor_test_1, y_pred_s))\n",
    "\n",
    "# confusion matrix \n",
    "print(confusion_matrix(Y_non_cor_test_1, y_pred_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
